{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "checkpoint_5.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "grateful-capital"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "id": "grateful-capital",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expected-rough"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "id": "expected-rough",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "light-surprise"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "id": "light-surprise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "numerical-enterprise",
        "outputId": "20643d3a-65c3-4fba-ee76-8a4cff67ff48"
      },
      "source": [
        "X_train[0].shape"
      ],
      "id": "numerical-enterprise",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "federal-munich"
      },
      "source": [
        "# In this task, you'll build an ANN and train and test it using the MNIST data. This ANN should consist of two hidden layers and one output layer. All of the hidden layers should be dense. The first layer and the second layer should have neuron sizes of 32 and 16, respectively. Train this model for 20 epochs, and compare your training and test set performance with the example in the checkpoint. Is there any difference? If so, why?"
      ],
      "id": "federal-munich"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "valued-arcade"
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(32, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "id": "valued-arcade",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "least-spain",
        "outputId": "eeb32265-3b4c-43d9-dfbf-ca38ce07801a"
      },
      "source": [
        "model.summary()"
      ],
      "id": "least-spain",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 25,818\n",
            "Trainable params: 25,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incredible-zimbabwe"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "id": "incredible-zimbabwe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advance-catering",
        "outputId": "e2663772-635b-4351-989b-34f316ec5557"
      },
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "id": "advance-catering",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 1.5597 - accuracy: 0.5290\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.8160: 0s - loss: 0.6842 - accuracy: 0.\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.86 - 1s 1ms/step - loss: 0.4777 - accuracy: 0.8666\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4021 - accuracy: 0.8872: 0s - loss: 0.4073 - accuracy: \n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3599 - accuracy: 0.8987: 0s - loss: 0.3628 - accuracy: 0.\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.9060 ETA: 0s - loss: 0.3366 - accuracy - ETA: 0s - loss: 0.3317 - accuracy:  - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9059\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.9113: 0s - loss: 0.3319 - \n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2988 - accuracy: 0.9146\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2868 - accuracy: 0.9178\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2758 - accuracy: 0.9219: 0s - loss: 0.2847 - accuracy - ETA: 0s - loss: 0.2771 - accuracy: 0.92 - ETA: 0s - loss: 0.2760 - accuracy: 0.\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.92 - 1s 1ms/step - loss: 0.2664 - accuracy: 0.9240\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2577 - accuracy: 0.9266\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.92 - 1s 1ms/step - loss: 0.2499 - accuracy: 0.9287\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.9315: 0s - loss: 0.2435 - accuracy:  - ETA: 0s - loss: 0.2464 - accuracy: 0.93 - ETA: 0s - loss: 0.2453 - accura\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2357 - accuracy: 0.9330: 0s - loss: 0.2351 - accuracy: 0.\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2293 - accuracy: 0.9346\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2232 - accuracy: 0.9366\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2175 - accuracy: 0.9379: 0s - loss: 0.2168 - accu\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2124 - accuracy: 0.9392: 0s - loss: 0.2094 - accura\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2075 - accuracy: 0.9404: 0s - loss: 0.2137 - accura - ETA: 0s - loss: 0.2076 - accuracy: 0.93 - ETA: 0s - loss: 0.2061 - accuracy: 0.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x21386113220>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "responsible-monitor",
        "outputId": "27e0d0e1-2d23-4c68-9e3e-3a3357e6363b"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "responsible-monitor",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.2009628713130951\n",
            "Test accuracy: 0.9409999847412109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incorporated-terminology"
      },
      "source": [
        "Looks like the model is not complicated enough, test accuracy is down, test loss is up compared to more complicated model"
      ],
      "id": "incorporated-terminology"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "closing-bottle"
      },
      "source": [
        "# In this task, build another ANN. This ANN should have five hidden layers and one output layer. All of the layers should be dense. The neuron numbers for the hidden layers should be 1024, 512, 256, 128, and 64. Train this model for 20 epochs, and test it using the same data from the previous task. Then compare your results. Is there any difference? If so, why?"
      ],
      "id": "closing-bottle"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "norman-hundred"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# The third dense layer\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
        "# The fourth dense layer\n",
        "model.add(Dense(126, activation=\"relu\"))\n",
        "# The fifth dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "id": "norman-hundred",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "detected-adoption"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "id": "detected-adoption",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "african-questionnaire",
        "outputId": "61d3afef-e34b-4dd9-8466-9c7d7d0e19f0"
      },
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "id": "african-questionnaire",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.2411 - accuracy: 0.6604\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.3790 - accuracy: 0.8937\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2849 - accuracy: 0.9183\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2402 - accuracy: 0.9307\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2082 - accuracy: 0.9405\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1847 - accuracy: 0.9466\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1643 - accuracy: 0.9523\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1488 - accuracy: 0.9570\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1345 - accuracy: 0.9609\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1224 - accuracy: 0.9646\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1125 - accuracy: 0.9676\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1032 - accuracy: 0.9698\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0957 - accuracy: 0.9717\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0879 - accuracy: 0.9747\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0817 - accuracy: 0.9762\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0758 - accuracy: 0.9783\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0703 - accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0653 - accuracy: 0.9818\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0603 - accuracy: 0.9833\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0558 - accuracy: 0.9844\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x213872f9670>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "authorized-china",
        "outputId": "2f1ec07e-8831-4030-ba28-27df4fea7206"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "authorized-china",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.0893574133515358\n",
            "Test accuracy: 0.9718000292778015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bizarre-france"
      },
      "source": [
        "There's a big difference. The model with more layers achieved better accuracy on test data. Because a more complicated model was able to learn hard cases the pevious model wasn't able to categorize."
      ],
      "id": "bizarre-france"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shared-cholesterol"
      },
      "source": [
        "# In this task, you'll implement several ANN models with different activation functions. For each, use the cross-entropy loss function as the loss function. Specifically, do the following:"
      ],
      "id": "shared-cholesterol"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "religious-concentrate"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
      ],
      "id": "religious-concentrate"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surgical-morgan",
        "outputId": "5b02a792-9491-4c12-af94-759ba67841f8"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "surgical-morgan",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0750 - accuracy: 0.7316\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.8672: 0s - loss: 0.5443 - accuracy\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4279 - accuracy: 0.8855: 0s - loss: 0.4294 - accuracy: 0.\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.8955\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 0.90 - 1s 2ms/step - loss: 0.3493 - accuracy: 0.9025\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.9075: 0s -\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.9117: 0s - loss: 0.3118 - accuracy: 0.91\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.9148\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.9182\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.9210: 0s - loss: 0.2760 - accuracy: 0.92\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2671 - accuracy: 0.9234: 0s - loss: 0.2665 - ac\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2587 - accuracy: 0.9263\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.9279: 0s - loss: 0\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.9308\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2371 - accuracy: 0.9326\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2308 - accuracy: 0.9346\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2248 - accuracy: 0.9368\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2192 - accuracy: 0.9382: 0s - loss: 0.2210 - \n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9402\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9412\n",
            "Test score: 0.20557160675525665\n",
            "Test accuracy: 0.9419000148773193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hungry-polymer"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
      ],
      "id": "hungry-polymer"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naval-stone",
        "outputId": "fa6e51fb-f94b-4a33-8f60-1458b9b61519"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "naval-stone",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.2954 - accuracy: 0.1214: 0s - loss: 2\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.2468 - accuracy: 0.2812\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.1924 - accuracy: 0.4320\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.1165 - accuracy: 0.5196\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.0092 - accuracy: 0.5884\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.8686 - accuracy: 0.6173\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.7047 - accuracy: 0.6609\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.5313 - accuracy: 0.6935\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.3608 - accuracy: 0.7233\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.2061 - accuracy: 0.7495\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0762 - accuracy: 0.7679: 0s - loss: 1.1167 -  - ETA: 0s - loss: 1.0989 - accuracy: 0.76 - ETA: 0s - loss: 1.0961 - accu\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9714 - accuracy: 0.7838\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.8878 - accuracy: 0.7963\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.8204 - accuracy: 0.8083\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7652 - accuracy: 0.8191\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7192 - accuracy: 0.8267\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6803 - accuracy: 0.8339\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6469 - accuracy: 0.8401\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.8456\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.8504\n",
            "Test score: 0.5627157092094421\n",
            "Test accuracy: 0.8604999780654907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "desperate-cinema"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
      ],
      "id": "desperate-cinema"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paperback-framing",
        "outputId": "e15cb5e5-2edc-42a4-8627-370168a820a9"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "paperback-framing",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.2107 - accuracy: 0.7014\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.8725\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8944\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.9051 ETA: 0s - loss: 0.3417 - accuracy:  - 1s 2ms/step - loss: 0.3403 - accuracy: 0.9054\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3133 - accuracy: 0.9115\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.9173\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.9213\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.9243: 0s - loss: 0.2\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9279\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.9309\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9346\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9370\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2142 - accuracy: 0.9391: 0s - loss: 0.2146 - \n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9414\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9434\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9453\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.9469\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.9484\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1741 - accuracy: 0.9502\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9517\n",
            "Test score: 0.16790008544921875\n",
            "Test accuracy: 0.9498999714851379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "offshore-reliance"
      },
      "source": [
        "Relu rectified linear units performed the best, then tanh, and sigmoid was the worst"
      ],
      "id": "offshore-reliance"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "metric-entrepreneur"
      },
      "source": [
        "# In this task, you'll implement the ANN models specified below. For each, use the hinge loss function as the loss function. Specifically, do the following:"
      ],
      "id": "metric-entrepreneur"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comfortable-insurance"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
      ],
      "id": "comfortable-insurance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shared-occasions",
        "outputId": "94cd40d7-0bb4-480f-9e6a-62d72f056afa"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='hinge',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "shared-occasions",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0768 - accuracy: 0.1710\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0704 - accuracy: 0.2594\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0627 - accuracy: 0.3649: 0s - loss: 1.0628 - accuracy: 0.36\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0537 - accuracy: 0.4338: \n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0438 - accuracy: 0.4710\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0338 - accuracy: 0.5024\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0246 - accuracy: 0.5370\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0163 - accuracy: 0.5818\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0085 - accuracy: 0.6231\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0016 - accuracy: 0.6468\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9960 - accuracy: 0.6651: 0s - loss: 0.9976 - accura - ETA: 0s - loss: 0.9966 - accuracy\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9912 - accuracy: 0.6793\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9871 - accuracy: 0.6901: 0s - loss: 0.9877 - accuracy\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9838 - accuracy: 0.6970\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9809 - accuracy: 0.7018\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9785 - accuracy: 0.7058: 0s - loss: 0.9787 - accuracy\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9764 - accuracy: 0.7092\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9746 - accuracy: 0.7121\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9729 - accuracy: 0.7149: 0s - l\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9715 - accuracy: 0.7171: 0s - loss: 0.9714 \n",
            "Test score: 0.9691101312637329\n",
            "Test accuracy: 0.7283999919891357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sunrise-vegetable"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
      ],
      "id": "sunrise-vegetable"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sharing-demographic",
        "outputId": "3837640b-3932-4dd7-ddc9-1f3d7ee10514"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='hinge',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "sharing-demographic",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0796 - accuracy: 0.1124\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0796 - accuracy: 0.1124\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0795 - accuracy: 0.1124\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0794 - accuracy: 0.1124: 0s - loss: 1.0794 - accu - ETA: 0s - loss: 1.0794 - accuracy\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0794 - accuracy: 0.1124: 0s - loss: 1.0794 - accuracy\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0793 - accuracy: 0.1124\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0792 - accuracy: 0.1124\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0791 - accuracy: 0.1124\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0790 - accuracy: 0.1124: 0s - loss:\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0789 - accuracy: 0.1124\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0788 - accuracy: 0.1124\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0787 - accuracy: 0.1124\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0787 - accuracy: 0.1124: 0s - loss:\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0786 - accuracy: 0.1124\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0785 - accuracy: 0.1124: 0s - - ETA: 0s - loss: 1.0784 - accuracy: 0.11\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0784 - accuracy: 0.1124\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0783 - accuracy: 0.1124\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0782 - accuracy: 0.1124: 0s - loss: 1.0782 - accura\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0781 - accuracy: 0.1124\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0780 - accuracy: 0.1124: \n",
            "Test score: 1.0777863264083862\n",
            "Test accuracy: 0.11349999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "retired-separation"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
      ],
      "id": "retired-separation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canadian-theory",
        "outputId": "d6305159-4785-472b-8a21-1c5c73f00089"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='hinge',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "canadian-theory",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0791 - accuracy: 0.1927\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0776 - accuracy: 0.2691\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0757 - accuracy: 0.3266\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0732 - accuracy: 0.3697\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0698 - accuracy: 0.3965\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0648 - accuracy: 0.4162\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0575 - accuracy: 0.4361\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0473 - accuracy: 0.4550\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0360 - accuracy: 0.4654\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0271 - accuracy: 0.4697\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0210 - accuracy: 0.4735\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0168 - accuracy: 0.4769\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0136 - accuracy: 0.4813\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0106 - accuracy: 0.4959\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0077 - accuracy: 0.5221: 0s\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0052 - accuracy: 0.5367\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0030 - accuracy: 0.5432: 0s - loss: 1.0032 - accuracy: \n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0012 - accuracy: 0.5477\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9996 - accuracy: 0.5515: 0s - loss: 0.9993 - accu\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9982 - accuracy: 0.5546\n",
            "Test score: 0.9970110058784485\n",
            "Test accuracy: 0.5587999820709229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affiliated-athens"
      },
      "source": [
        "crossenthropy loss function performed best"
      ],
      "id": "affiliated-athens"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intensive-understanding"
      },
      "source": [
        "# In this assignment, you'll continue working on the MNIST dataset. So, train and test the models specified in the tasks below using the MNIST data. You can choose the number of epochs for training. But for the sake of comparison, it's a good idea to train for 20 epochs.\n",
        "\n",
        "To complete this assignment, create a Jupyter Notebook containing your solutions to the following tasks:"
      ],
      "id": "intensive-understanding"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flexible-particular"
      },
      "source": [
        "## In this task, you'll implement several ANN models with different batch sizes. Specifically, do the following:"
      ],
      "id": "flexible-particular"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "needed-support"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 8 as the mini-batch size."
      ],
      "id": "needed-support"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "proprietary-douglas",
        "outputId": "c9470a71-3522-4d93-ebe4-cf53fd727815"
      },
      "source": [
        "batch_size=8\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "proprietary-douglas",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7500/7500 [==============================] - 7s 892us/step - loss: 0.3732 - accuracy: 0.89416s - loss: 1.2982 - accu - ETA: 6s - loss: 1.0108 - accuracy:  - ETA: 6s - loss: 0.9255 - ac - ETA: 5s - loss: 0.7827 - accuracy:  - ETA: 5s - loss: 0.7384 - accuracy:  - ETA: 5s - loss: 0.7004 - accuracy: 0. - ETA: 5s - loss: 0.6787 - accuracy: 0. - ETA: 5s - loss: 0.6609 - accuracy:  - ETA: 4s - loss: 0.6364 - accuracy: 0.82 - ETA: 4s - loss: 0.6295  - ETA: 3s - loss: 0.4875 - accuracy: 0.86 - ETA: \n",
            "Epoch 2/20\n",
            "7500/7500 [==============================] - 7s 913us/step - loss: 0.1754 - accuracy: 0.94914s - loss: 0.199 - ETA:  - ETA: 3s - loss: - ETA: 1s - los - ETA: 0s - loss: 0.1757 - accuracy: 0.\n",
            "Epoch 3/20\n",
            "7500/7500 [==============================] - 7s 925us/step - loss: 0.1267 - accuracy: 0.96332s - loss: 0.1312 - accuracy - ETA: 2s - ETA: 1s - loss: 0.1303 - accuracy: 0. - ETA: 1s - loss: 0.1307 - accuracy: 0. - ETA: 1s - loss: 0.1312 - \n",
            "Epoch 4/20\n",
            "7500/7500 [==============================] - 8s 1ms/step - loss: 0.0993 - accuracy: 0.9705: 5s - loss: 0.1057 - accuracy: 0.96 - ETA: 5s - loss: 0.1041 - accu - ETA: 5s - - ETA - ETA: 1s - loss: 0.1008 - accuracy: 0.97 - ETA: 1s - ETA: 0s - loss: 0.0999 - accura - ETA: 0s - loss: 0.099\n",
            "Epoch 5/20\n",
            "7500/7500 [==============================] - 7s 921us/step - loss: 0.0802 - accuracy: 0.97627s - loss: 0.0703 - ac - ETA: 6s - loss: 0.0711 - accuracy:  - ETA: 6s - loss: 0.0736 - accura - ETA: 6s - loss: 0.0750 - accuracy: 0.97 - ETA: 6s - loss: 0.0751 \n",
            "Epoch 6/20\n",
            "7500/7500 [==============================] - 7s 905us/step - loss: 0.0677 - accuracy: 0.9803\n",
            "Epoch 7/20\n",
            "7500/7500 [==============================] - 7s 985us/step - loss: 0.0574 - accuracy: 0.9828: 1s - loss: 0.0582 - accuracy:  - ETA: 1s - loss: - ETA: 0s - loss: 0.0580 - ac\n",
            "Epoch 8/20\n",
            "7500/7500 [==============================] - 7s 898us/step - loss: 0.0494 - accuracy: 0.9853\n",
            "Epoch 9/20\n",
            "7500/7500 [==============================] - 7s 918us/step - loss: 0.0424 - accuracy: 0.9877:  - ETA: 4s - loss: 0.0417 - accura - ETA: 4s - loss: 0.0414 - accuracy:  - ETA: 3s - loss: 0.0415 - accuracy:  - ETA: 3s - loss: 0.0418 - accura - ETA: 3s - los - ETA: 2s - loss: 0.0 - ETA: 1s - loss: 0.0420 - accuracy:  - ETA: 0s - loss: 0.0425 - accuracy: 0.98 - ETA: 0s - loss: 0.0426 - accuracy - ETA: 0s - loss: 0.0426 - accuracy: 0. - ETA: 0s - loss: 0.0425 - accura - ETA: 0s - loss: 0.0427 - ac\n",
            "Epoch 10/20\n",
            "7500/7500 [==============================] - 7s 942us/step - loss: 0.0368 - accuracy: 0.98956s - loss: 0.0263 - accuracy: 0. - ETA: 6s - loss: 0.0310 - accuracy: 0. - ETA: 6s - loss: 0 - ETA: 5s - loss: 0.0313 - accuracy:  - ETA: 5s - loss: 0.0304 - accuracy - ETA - ETA: 0s - loss: 0.0367 - accuracy\n",
            "Epoch 11/20\n",
            "7500/7500 [==============================] - 8s 1ms/step - loss: 0.0309 - accuracy: 0.9912: 7s - loss: 0.0264 - accuracy - ETA: 6s - loss: 0.0287 - accuracy - ETA:  - ETA: 2s - loss: 0.0 - ETA: 2s - loss: 0.0305 - accuracy: 0.\n",
            "Epoch 12/20\n",
            "7500/7500 [==============================] - 7s 966us/step - loss: 0.0273 - accuracy: 0.99261s - los - ETA: 0s - loss: 0.0274 - \n",
            "Epoch 13/20\n",
            "7500/7500 [==============================] - 7s 924us/step - loss: 0.0239 - accuracy: 0.9935 ETA: 2s - loss: 0.0226 - accuracy: 0.99 - ETA: 2s - loss: 0.0226 -  - ETA: 2s - loss: 0.0226 - accuracy: 0.99 - ETA: 2s - loss: 0.0228 - accu - ETA: 2s - loss: - ETA: 1s - loss: 0.0225 - accuracy: 0. - ETA: 1s - loss: 0.0227 -  - ETA: 1s - loss: 0.0233 - accuracy - ETA: 0s - loss: 0.0232 - accura - ETA: 0s - l\n",
            "Epoch 14/20\n",
            "7500/7500 [==============================] - 7s 920us/step - loss: 0.0205 - accuracy: 0.99507s - loss: 0.0169 - accuracy: 0.99 - - ETA: 5s - loss: 0.0180 - accuracy: 0. - ETA: 5s - loss: 0.0175 -  - ETA: 5s - loss: 0.0185  - ETA: 4s - loss: 0.0182  - ETA: 1s - loss: 0.020 - ETA: 1s - loss: 0.0202  - ETA: 0s - loss: 0.0200 - accu - ETA: 0s - loss: 0\n",
            "Epoch 15/20\n",
            "7500/7500 [==============================] - 7s 915us/step - loss: 0.0173 - accuracy: 0.99597s - loss: 0.0120 - accuracy - ETA: 7s - loss: 0.0163 - accuracy: 0.99 - ETA: 7s - loss: 0.0155 - accuracy: 0.99 - ETA: 7s - loss: 0.0157  - ETA: 6s - loss: 0.0152 - accu - ETA:  - ETA: 4s - loss: 0.0165 - accuracy: 0.99 - ETA: 4s - loss: 0.0166 - accura - ETA: 4s - - ETA: 3s - loss: 0.016 - ETA: 3s - los - ETA: 2s - loss: 0.016 - ETA: 1s - loss: 0.0168 - accu - - ETA: 0s - loss: 0\n",
            "Epoch 16/20\n",
            "7500/7500 [==============================] - 7s 909us/step - loss: 0.0155 - accuracy: 0.9963 - ETA: 5s - los - ETA: 4s - loss: 0.0151 - accuracy: 0.99 - ETA: 4s - loss: 0.0152 - accuracy - ETA: 4s - loss: 0.0147 - accu - ETA: 4s - loss: 0.0145 - accuracy:  - ETA: 4s - loss: 0.0142 - accuracy: 0. - ETA: 4s - los - ETA: 3s - loss: 0.0142 - accuracy - ETA: 2s - loss: 0 - ETA: 0s - loss: 0.0154 - ac\n",
            "Epoch 17/20\n",
            "7500/7500 [==============================] - 7s 952us/step - loss: 0.0141 - accuracy: 0.99642s - loss: 0.013 - ETA: 2s - los - ETA: 0s - loss: 0.014\n",
            "Epoch 18/20\n",
            "7500/7500 [==============================] - 7s 879us/step - loss: 0.0113 - accuracy: 0.99793s - loss: 0.0100 - accura - E\n",
            "Epoch 19/20\n",
            "7500/7500 [==============================] - 7s 998us/step - loss: 0.0103 - accuracy: 0.99806s - loss: 0.008 - ETA: 6s - loss: 0.0089 - accura - ETA: 6s\n",
            "Epoch 20/20\n",
            "7500/7500 [==============================] - 7s 897us/step - loss: 0.0085 - accuracy: 0.9986: 5s - - ETA: 4s - loss: - ETA: 4s - - ETA: 3s - loss: 0.0082 -  - ETA: 2s - loss: 0.0\n",
            "Test score: 0.0726034864783287\n",
            "Test accuracy: 0.9797999858856201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twenty-leave"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 128 as the mini-batch size."
      ],
      "id": "twenty-leave"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bored-vintage",
        "outputId": "fb36015a-6528-4ed4-a7e9-4e86239bd272"
      },
      "source": [
        "batch_size=128\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "bored-vintage",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 1.4428 - accuracy: 0.6019\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.8535: 0s - loss: 0.6393 - accura - ETA: 0s - loss: 0.5909 - accuracy\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8878\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.9010: 0s - loss: 0.3599 \n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.9093\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.9149\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.92 - 1s 2ms/step - loss: 0.2773 - accuracy: 0.9201\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2631 - accuracy: 0.9243\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9282: 0s - loss: 0.250\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.9312\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2296 - accuracy: 0.9340\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9364\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2123 - accuracy: 0.9395\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2044 - accuracy: 0.9414\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9437: 0s - loss: 0.1973 - accu\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9449\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9474\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.9488\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.9506\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1679 - accuracy: 0.9521\n",
            "Test score: 0.17021048069000244\n",
            "Test accuracy: 0.949999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dangerous-whale"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the full sample as the batch size."
      ],
      "id": "dangerous-whale"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bearing-arrangement",
        "outputId": "ee1eb9c2-6695-414c-8665-e1a07ccb0442"
      },
      "source": [
        "batch_size=784\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "bearing-arrangement",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "77/77 [==============================] - 1s 5ms/step - loss: 2.1446 - accuracy: 0.3121\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 1.7481 - accuracy: 0.6181\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 1.3263 - accuracy: 0.7452\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 1.0014 - accuracy: 0.7939\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.8032 - accuracy: 0.8217\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.6833 - accuracy: 0.8391\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.8519\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.5511 - accuracy: 0.8617\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.8691\n",
            "Epoch 10/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.8750\n",
            "Epoch 11/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.8802\n",
            "Epoch 12/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8843\n",
            "Epoch 13/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8874\n",
            "Epoch 14/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.4047 - accuracy: 0.8906\n",
            "Epoch 15/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3923 - accuracy: 0.8935\n",
            "Epoch 16/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3815 - accuracy: 0.8957\n",
            "Epoch 17/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8977\n",
            "Epoch 18/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8999\n",
            "Epoch 19/20\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3555 - accuracy: 0.9015\n",
            "Epoch 20/20\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3484 - accuracy: 0.9039\n",
            "Test score: 0.3328608572483063\n",
            "Test accuracy: 0.9068999886512756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "passing-defensive"
      },
      "source": [
        "The smaller batch size performed the best. The weights were updated more often, resulting in higher accuracy model"
      ],
      "id": "passing-defensive"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "refined-shoulder"
      },
      "source": [
        "## In this task, you'll implement several ANN models with different learning rates for the stochastic gradient descent. In all of the models below, use 128 as your mini-batch size."
      ],
      "id": "refined-shoulder"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parallel-madonna"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 0.01 as the learning rate."
      ],
      "id": "parallel-madonna"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "homeless-sport",
        "outputId": "384165e5-b0b6-49db-ccc5-148ddcb926e7"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "lr=0.01\n",
        "batch_size=128\n",
        "opt=SGD(lr=lr)\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "homeless-sport",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.2661 - accuracy: 0.6708: 0s - loss: 1.5445 - accuracy: 0.59 - ETA: 0s - loss: 1.4786 - accura\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.8630: 0s - los\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3980 - accuracy: 0.8909: 0s - loss: 0.4094 - \n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.9027\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.9099: 0s - loss: 0.3242 - accura\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.9156\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.9203: 0s - loss: 0.2837 \n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.9237\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2555 - accuracy: 0.9270\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.9300: 0s - loss: 0.2415 - accuracy: 0.\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2351 - accuracy: 0.9326\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2260 - accuracy: 0.9353: 0s - loss: 0.227\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9376: 0s - loss: 0.2203 - ac\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9394\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2030 - accuracy: 0.9424\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9438\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1899 - accuracy: 0.9459\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9480 ETA: 0s - loss: 0.1823 - accura - 1s 2ms/step - loss: 0.1838 - accuracy: 0.9480\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.9488\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.9503\n",
            "Test score: 0.17112569510936737\n",
            "Test accuracy: 0.9495000243186951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "occupational-tolerance"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 100 as the learning rate."
      ],
      "id": "occupational-tolerance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "disabled-maintenance",
        "outputId": "7326fdcc-50bc-4ec1-85e4-93d668b8a9e3"
      },
      "source": [
        "lr=100\n",
        "batch_size=128\n",
        "opt=SGD(lr=lr)\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "disabled-maintenance",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 2ms/step - loss: nan - accuracy: 0.0987\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - a\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy: 0.10 - ETA: 0s - loss: nan - \n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - ac\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accurac\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - a\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy: 0.09\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy: 0.09 - ETA: 0s - loss: nan - accuracy:\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy:  - ETA: 0s - loss: nan - accuracy: 0.\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - a\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accurac\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - acc\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - ac\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0987A: 0s - loss: nan - accuracy - ETA: 0s - loss: nan - accurac\n",
            "Test score: nan\n",
            "Test accuracy: 0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "remarkable-signature"
      },
      "source": [
        "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use 0.0000001 as the learning rate."
      ],
      "id": "remarkable-signature"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlike-complement",
        "outputId": "134699f7-97e0-4ef8-c991-d8d3c0551fcc"
      },
      "source": [
        "lr=0.0000001\n",
        "batch_size=128\n",
        "opt=SGD(lr=lr)\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "unlike-complement",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3828 - accuracy: 0.0990\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3828 - accuracy: 0.0990: 0s - loss: 2.3824 - accuracy: 0.09 - ETA: 0s - loss: 2.3827 - accuracy: 0.09\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 2.3827 - accuracy: 0.09 - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990: 0s - los\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3827 - accuracy: 0.0990\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3826 - accuracy: 0.0990\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3826 - accuracy: 0.0990: 0s - loss: 2.3810 - accuracy - ETA: 0s - loss: 2.3830 - ac\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3826 - accuracy: 0.0990\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3826 - accuracy: 0.0990\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3826 - accuracy: 0.0990\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3826 - accuracy: 0.0990\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3825 - accuracy: 0.0990\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3825 - accuracy: 0.0990: 0s - loss: 2.3834 - accuracy:  - ETA: 0s - loss: 2.3830 - accuracy: 0.09 - ETA: 0s - loss: 2.3828 - accuracy: 0.\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3825 - accuracy: 0.0990\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3825 - accuracy: 0.0990\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.3825 - accuracy: 0.0990: 0s - loss: 2.3811 - accuracy - ETA: 0s - loss: 2.3817 - accuracy: 0.09 - ETA: 0s - loss: 2.3822 - accuracy - ETA: 0s - loss: 2.3824 - accuracy: 0.09 - ETA: 0s - loss: 2.3843 - accura\n",
            "Test score: 2.3856022357940674\n",
            "Test accuracy: 0.10459999740123749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hearing-welcome"
      },
      "source": [
        "whel lr was too small or too high it never found the globl minimum. When it was too low it didn't have enough epochs,\n",
        "when t was too high it was bouncing around local minimum too much, neve converging"
      ],
      "id": "hearing-welcome"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colonial-flour"
      },
      "source": [
        ""
      ],
      "id": "colonial-flour",
      "execution_count": null,
      "outputs": []
    }
  ]
}