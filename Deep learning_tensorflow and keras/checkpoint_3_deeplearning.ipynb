{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "checkpoint_3_deeplearning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mighty-pharmaceutical"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "id": "mighty-pharmaceutical",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bronze-broadcasting"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "id": "bronze-broadcasting",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "integral-deficit"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "id": "integral-deficit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impressive-bible",
        "outputId": "55691627-2334-4c2d-d213-89d8c13426da"
      },
      "source": [
        "X_train[0].shape"
      ],
      "id": "impressive-bible",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ranging-couple"
      },
      "source": [
        "# In this task, you'll build an ANN and train and test it using the MNIST data. This ANN should consist of two hidden layers and one output layer. All of the hidden layers should be dense. The first layer and the second layer should have neuron sizes of 32 and 16, respectively. Train this model for 20 epochs, and compare your training and test set performance with the example in the checkpoint. Is there any difference? If so, why?"
      ],
      "id": "ranging-couple"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ranking-disco"
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(32, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "id": "ranking-disco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empty-demand",
        "outputId": "c49405fc-9fad-4cde-9205-3e12a789d6df"
      },
      "source": [
        "model.summary()"
      ],
      "id": "empty-demand",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 25,818\n",
            "Trainable params: 25,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acknowledged-letter"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "id": "acknowledged-letter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miniature-mirror",
        "outputId": "4b0fa316-aa5d-4c22-f16f-72ea286c30cd"
      },
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "id": "miniature-mirror",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 1.6838 - accuracy: 0.4814\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.7761 - accuracy: 0.8127\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.8635\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4156 - accuracy: 0.8820\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3771 - accuracy: 0.8917: 0s - loss: 0.3859 - accuracy: 0.88 - ETA: 0s - loss: 0.3821 - accuracy\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.89 - 1s 1ms/step - loss: 0.3520 - accuracy: 0.8982\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9035: 0s - loss: 0\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3175 - accuracy: 0.9076\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3044 - accuracy: 0.9117\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.9155\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2821 - accuracy: 0.9185: 0s - loss: 0.2816 - accuracy: \n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2729 - accuracy: 0.9214: 0s - loss: 0.2741 - \n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2638 - accuracy: 0.9242: 0s - loss: 0.2632 - accuracy: 0.92\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2558 - accuracy: 0.9265: 0s - loss: 0.2552 - accuracy: 0.\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2482 - accuracy: 0.9286\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2408 - accuracy: 0.9314\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2340 - accuracy: 0.9329: 0s - loss: 0\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2274 - accuracy: 0.9351\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9369\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2152 - accuracy: 0.9380: 0s - loss: 0.2165 - accuracy: 0.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1a6070309d0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "indian-disposition",
        "outputId": "4d94bd58-26ab-41a4-e1f8-667a9da4d218"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "indian-disposition",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.21391651034355164\n",
            "Test accuracy: 0.9365000128746033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "recorded-blank"
      },
      "source": [
        "Looks like the model is not complicated enough, test accuracy is down, test loss is up compared to more complicated model"
      ],
      "id": "recorded-blank"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "black-charleston"
      },
      "source": [
        "# In this task, build another ANN. This ANN should have five hidden layers and one output layer. All of the layers should be dense. The neuron numbers for the hidden layers should be 1024, 512, 256, 128, and 64. Train this model for 20 epochs, and test it using the same data from the previous task. Then compare your results. Is there any difference? If so, why?"
      ],
      "id": "black-charleston"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "natural-prevention"
      },
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# The third dense layer\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
        "# The fourth dense layer\n",
        "model.add(Dense(126, activation=\"relu\"))\n",
        "# The fifth dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "id": "natural-prevention",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expensive-greenhouse"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "id": "expensive-greenhouse",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pleasant-holiday",
        "outputId": "231fb0b2-3b27-49e1-fe15-96cdfe2ef46e"
      },
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "id": "pleasant-holiday",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.2566 - accuracy: 0.6525\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3717 - accuracy: 0.8954\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2798 - accuracy: 0.9200\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2336 - accuracy: 0.9333\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2024 - accuracy: 0.9418\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1790 - accuracy: 0.9489\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1605 - accuracy: 0.9545\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1465 - accuracy: 0.9583\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1337 - accuracy: 0.9615\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.1230 - accuracy: 0.9653\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1130 - accuracy: 0.9679\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1041 - accuracy: 0.9704\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0969 - accuracy: 0.9719\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0897 - accuracy: 0.9745\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0833 - accuracy: 0.9759\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0772 - accuracy: 0.9779\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0717 - accuracy: 0.9798\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0670 - accuracy: 0.9807\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0624 - accuracy: 0.9823\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.0574 - accuracy: 0.9839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1a607271d60>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "earned-coating",
        "outputId": "c122a649-4d6c-483f-9c6b-62743019852c"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "earned-coating",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score: 0.08474591374397278\n",
            "Test accuracy: 0.9739999771118164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "breathing-theology"
      },
      "source": [
        "There's a big difference. The model with more layers achieved better accuracy on test data. Because a more complicated model was able to learn hard cases the pevious model wasn't able to categorize."
      ],
      "id": "breathing-theology"
    }
  ]
}